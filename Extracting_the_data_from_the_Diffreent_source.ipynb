{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOm9bhMWVZlkPZ6QOGX1E2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baaaRaathh/Natural-Language-Processing/blob/main/Extracting_the_data_from_the_Diffreent_source.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting the data from Pdf"
      ],
      "metadata": {
        "id": "vHYb7U4uc9ZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY4Y8BBKLM1h",
        "outputId": "93a6e556-6276-46d6-a056-351bdeed455c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDf2\n",
            "Successfully installed PyPDf2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDf2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from PyPDF2 import PdfFileReader\n",
        "pdf = open('ResumeDS.pdf','rb')\n",
        "read = PyPDF2.PdfReader(pdf)"
      ],
      "metadata": {
        "id": "mSKa4ZPSNESf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(read.pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvdOlhlwOAke",
        "outputId": "56d9efd3-dd12-4754-9e53-0cdafe1766b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page = read.pages[0]"
      ],
      "metadata": {
        "id": "RItv0YwLOS9Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page.extract_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "humypCW-OGyd",
        "outputId": "b1715304-69c9-4d4b-d40e-e82aadcba6eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024 \n",
            "2023 \n",
            "2020   2024 July 2023(1 Month)\n",
            "Tiruchirapalli\n",
            "TiruchirapalliTiruchirapalli\n",
            "Tiruchirappalli\n",
            "Tiruchirapalli, TamilNaduArtiﬁcial Intelligence Based Health Management App\n",
            "B.E BioMedical Engineering\n",
            "Dhanalakshmi Srinivasan Institue  of technology\n",
            "Samayapuram,TiruchirappalliData Science Intern\n",
            "KIWISTRONSKILLS\n",
            "AI-powered Health Management App for medical advice, image\n",
            "analysis, and nutrition tracking\n",
            "•Led a 4-member team to create an AI-powered Health Management \n",
            "App with a medical chatbot and image analyzer using the Google \n",
            "Gemini Pro API.Internship focusing on data Science\n",
            "•Experienced in Python for building and fine-tuning machine learning\n",
            "models. \n",
            "Developed and presented predictive models that improved stakeholder\n",
            "understanding of complex data insights.•\n",
            "Internship with a focus on python and Data Maniplution.\n",
            "•\n",
            "•\n",
            "•Experienced in Python for efficient data manipulation and analysis.\n",
            "Processed over  datasets using Python and SQL.\n",
            "Participated in a team project to enhance data quality, achieving a 20% \n",
            "improvement in data accuracy.\n",
            "Risk Prediction Using Machine Learning\n",
            "•The project predicts maternal health risks using machine learning \n",
            "models, focusing on data preprocessing, model training, and evaluation \n",
            "to classify risk levels accuratelyPython Intern\n",
            "SD Pro Solution\n",
            "Maternal Health Risk Prediction Using Machine\n",
            "LearningPython\n",
            "SQL\n",
            "Data Structure \n",
            "Numpy\n",
            "Pandas\n",
            "Matplotlib & Seabron\n",
            "Data Manipulation\n",
            "Data Analysis\n",
            "Tableau & Data Visualization\n",
            "Machine learning Algorithm\n",
            "Scikit-learn & PyTroch & Tensorflow\n",
            "Deep Learning & NLP \n",
            "Opencv(Computer Vision)\n",
            "Microsoft AZUR Cloud\u0000\n",
            "Eager to apply my strong data analysis skills in a dynamic environment,\n",
            "with proven expertise in Python, machine learning, and AI. I have\n",
            "experience developing and optimizing machine learning models,\n",
            "collaborating with cross-functional teams, and delivering actionable\n",
            "insights. Proficient in tools like NumPy, Pandas, Matplotlib, and scikit-learn,\n",
            "I am passionate about contributing to innovative, data-centric projects and\n",
            "driving impactful, data-driven decision-making.OBJECTIVEBARATH KUMAR S\n",
            "Data Science | Machine Learning \n",
            "barathkumar112003@gmail.com https://www.linkedin.com/in/barath55/\n",
            "Tiruchirapalli ,Tamil Nadu| https://github.com/baaaRaathh/pythons LinkedIn - Github -\n",
            "6379109925 Mob No - ||\n",
            "HackerRank -https://www.hackerrank.com/dashboard |\n",
            "PROJECTS\n",
            "EDUCATIONEXPERIENCE\n",
            "CERTIFICATIONLocation -\n",
            "Mar 2024 - Aug 2024(6 Month)\n",
            "DOMAIN KNOWLEDGE\n",
            "Scored -  8.2 CGPA Expertise in data analysis, predictive modeling,\n",
            "machine learning algorithms, and deep learning\n",
            "techniques, with real-world project experience.\n",
            "Proficient in Python, SQL, and key libraries\n",
            "such as NumPy, Pandas, Matplotlib, Seaborn,\n",
            "scikit-learn, and OpenCV for data\n",
            "manipulation, visualization, and model training\n",
            ".\n",
            "Skilled in AI-driven projects, including\n",
            "developing medical chatbots and image\n",
            "analyzers, and working with NLP for language\n",
            "processing tasks.\n",
            "Completed impactful projects like AI-based\n",
            "health assistants, perinatal health risk\n",
            "prediction, and crime pattern analysis for safer\n",
            "route prediction.\n",
            "Worked as a Data Science Intern at Kiwistron,\n",
            "gaining hands-on experience in data analysis,\n",
            "machine learning, and algorithm optimization.\u0000\n",
            "Completed a one-day Data Science workshop\n",
            "by Gateway.\n",
            " Completed an Applied Data Science\n",
            "certificate from IBM.\n",
            " Completed a Networking and Web\n",
            "Technology certificate from Infosys.\n",
            " Completed comprehensive SQL training by\n",
            "GeeksforGeeks, covering advanced querying,\n",
            "database management, and data manipulation\n",
            "techniques.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnLT5hYGOPRg",
        "outputId": "6e4d2fb7-ec64-4a35-d688-f421330a2db4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/Type': '/Page',\n",
              " '/Resources': {'/ProcSet': ['/PDF', '/Text', '/ImageB', '/ImageC', '/ImageI'],\n",
              "  '/ExtGState': {'/G3': {'/ca': 1, '/BM': '/Normal'}},\n",
              "  '/XObject': {'/X4': {'/Type': '/XObject',\n",
              "    '/Subtype': '/Image',\n",
              "    '/Width': 1216,\n",
              "    '/Height': 3,\n",
              "    '/ColorSpace': ['/ICCBased', IndirectObject(116, 0, 140564452514960)],\n",
              "    '/SMask': {'/Type': '/XObject',\n",
              "     '/Subtype': '/Image',\n",
              "     '/Width': 1216,\n",
              "     '/Height': 3,\n",
              "     '/ColorSpace': '/DeviceGray',\n",
              "     '/BitsPerComponent': 8,\n",
              "     '/Filter': '/FlateDecode'},\n",
              "    '/BitsPerComponent': 8,\n",
              "    '/Filter': '/FlateDecode'},\n",
              "   '/X7': {'/Type': '/XObject',\n",
              "    '/Subtype': '/Image',\n",
              "    '/Width': 1216,\n",
              "    '/Height': 3,\n",
              "    '/ColorSpace': ['/ICCBased', IndirectObject(116, 0, 140564452514960)],\n",
              "    '/SMask': {'/Type': '/XObject',\n",
              "     '/Subtype': '/Image',\n",
              "     '/Width': 1216,\n",
              "     '/Height': 3,\n",
              "     '/ColorSpace': '/DeviceGray',\n",
              "     '/BitsPerComponent': 8,\n",
              "     '/Filter': '/FlateDecode'},\n",
              "    '/BitsPerComponent': 8,\n",
              "    '/Filter': '/FlateDecode'}},\n",
              "  '/Font': {'/F9': {'/Type': '/Font',\n",
              "    '/Subtype': '/Type0',\n",
              "    '/BaseFont': '/AAAAAA+Inter-Regular',\n",
              "    '/Encoding': '/Identity-H',\n",
              "    '/DescendantFonts': [IndirectObject(154, 0, 140564452514960)],\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'}},\n",
              "   '/F10': {'/Type': '/Font',\n",
              "    '/Subtype': '/Type0',\n",
              "    '/BaseFont': '/BAAAAA+Inter-Bold',\n",
              "    '/Encoding': '/Identity-H',\n",
              "    '/DescendantFonts': [IndirectObject(156, 0, 140564452514960)],\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'}},\n",
              "   '/F11': {'/Type': '/Font',\n",
              "    '/Subtype': '/Type0',\n",
              "    '/BaseFont': '/CAAAAA+Rubik-Regular',\n",
              "    '/Encoding': '/Identity-H',\n",
              "    '/DescendantFonts': [IndirectObject(158, 0, 140564452514960)],\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'}},\n",
              "   '/F12': {'/Type': '/Font',\n",
              "    '/Subtype': '/Type0',\n",
              "    '/BaseFont': '/DAAAAA+Rubik-Medium',\n",
              "    '/Encoding': '/Identity-H',\n",
              "    '/DescendantFonts': [IndirectObject(160, 0, 140564452514960)],\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'}},\n",
              "   '/F13': {'/Type': '/Font',\n",
              "    '/Subtype': '/Type0',\n",
              "    '/BaseFont': '/EAAAAA+Arimo-Regular',\n",
              "    '/Encoding': '/Identity-H',\n",
              "    '/DescendantFonts': [IndirectObject(162, 0, 140564452514960)],\n",
              "    '/ToUnicode': {'/Filter': '/FlateDecode'}}}},\n",
              " '/MediaBox': [0, 7.8299813, 595.5, 850.07996],\n",
              " '/Annots': [IndirectObject(14, 0, 140564452514960),\n",
              "  IndirectObject(15, 0, 140564452514960),\n",
              "  IndirectObject(16, 0, 140564452514960)],\n",
              " '/Contents': [IndirectObject(17, 0, 140564452514960),\n",
              "  IndirectObject(18, 0, 140564452514960),\n",
              "  IndirectObject(19, 0, 140564452514960)],\n",
              " '/StructParents': 0,\n",
              " '/Parent': {'/Type': '/Pages',\n",
              "  '/Kids': [IndirectObject(7, 0, 140564452514960)],\n",
              "  '/Count': 1},\n",
              " '/Tabs': '/S',\n",
              " '/BleedBox': [0, 7.8299813, 595.5, 850.07996],\n",
              " '/TrimBox': [0, 7.8299813, 595.5, 850.07996],\n",
              " '/CropBox': [0, 7.8299813, 595.5, 850.07996],\n",
              " '/Rotate': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting the data from Word file"
      ],
      "metadata": {
        "id": "B-wZnCKfdEwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWGslDHdQX2u",
        "outputId": "9ca22fae-240d-4c45-b289-fd581c6b0077"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "doc = Document('Barath Analyst.doc')"
      ],
      "metadata": {
        "id": "exYmpSnWdVRq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from Paragraph\n",
        "text =[]\n",
        "for pargh in doc.paragraphs:\n",
        "  text.append(pargh.text)"
      ],
      "metadata": {
        "id": "wAI4K7COd0DC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amifLjoNeGfS",
        "outputId": "f6330689-74da-4d0d-9022-be20f6313795"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BARATH KUMAR S',\n",
              " 'Data Analyst | Data Visualization | SQL Expert',\n",
              " 'barathkumar112003@gmail.com | LinkedIn - https://www.linkedin.com/in/barath55/ | Github - https://github.com/baaaRaathh/p y thons',\n",
              " '',\n",
              " 'HackerRank - https://www.hackerrank.com/dashboard',\n",
              " '',\n",
              " 'OBJECTIVE',\n",
              " '|Mob No - 6379109925 |Location - Tiruchirapalli ,Tamil Nadu',\n",
              " '',\n",
              " 'STRENGTHS',\n",
              " '',\n",
              " '',\n",
              " 'Eager to apply my data analysis skills in a dynamic environment. Skilled in SQL, Python, and data visualization. Aspiring to contribute to data-driven decision-making processes and eager to develop further in data analytics.',\n",
              " 'EXPERIENCE',\n",
              " '',\n",
              " 'Data Science Intern',\n",
              " 'KIWISTRON',\n",
              " '',\n",
              " 'Analytical Thinking',\n",
              " 'Proven ability to analyze complex datasets, as demonstrated during my internship at IBM, leading to actionable insights.',\n",
              " '',\n",
              " '',\n",
              " 'Effective Communication',\n",
              " 'Skilled in presenting complex data in an understandable format, evidenced by',\n",
              " '',\n",
              " '2023 2024',\n",
              " 'Tiruchirapalli',\n",
              " 'positive feedback from Accenture team',\n",
              " '',\n",
              " 'Internship focusing on data Science',\n",
              " 'Analyzed large datasets using SQL and Python, identifying key trends and patterns, which improved data-driven decision-making by 30%.',\n",
              " 'Developed and presented data-driven insights, improving stakeholder understanding of complex dataset.',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'leads.',\n",
              " '',\n",
              " '',\n",
              " 'Team Collaboration',\n",
              " 'Excelled in team projects, contributing to a 20% improvement in data quality at',\n",
              " '',\n",
              " 'Python Intern',\n",
              " 'SD Pro Solution',\n",
              " '2023 2023',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'Cleveland, OH',\n",
              " 'Accenture through effective collaboration.',\n",
              " '',\n",
              " 'SKILLS',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'Internship with a focus on python and Data Maniplution.',\n",
              " '',\n",
              " 'Experienced in Python for efficient data manipulation and analysis.',\n",
              " 'Processed over 50 datasets using Python and SQL.',\n",
              " 'Participated in a team project to enhance data quality, achieving a 20%',\n",
              " 'improvement in data accuracy.',\n",
              " 'SQL\\tPython\\tData Visualization',\n",
              " '',\n",
              " '  ',\n",
              " '',\n",
              " 'Tableau\\tPowerBi\\tExcel',\n",
              " '',\n",
              " '  ',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'PROJECTS',\n",
              " '',\n",
              " '',\n",
              " 'Artiﬁcial Intelligence Based Health Management App',\n",
              " 'Data Manipulation Data Management',\n",
              " 'Data Analysis',\n",
              " '',\n",
              " '',\n",
              " 'Report Generation',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '2024',\n",
              " 'Tiruchirapalli',\n",
              " 'CERTIFICATION',\n",
              " '',\n",
              " 'AI-powered Health Management App for medical advice, image analysis, and nutrition tracking',\n",
              " '',\n",
              " 'Led a 4-member team to create an AI-powered Health Management App with a medical chatbot and image analyzer using the Google Gemini Pro API.',\n",
              " '',\n",
              " '',\n",
              " 'Maternal Health Risk Prediction Using Machine Learning',\n",
              " 'Applied Data Science',\n",
              " 'Completed an in-depth course on Applied Data Science through Coursera, with a strong focus on complex data analysis, manipulation, and advanced querying techniques',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'SQL',\n",
              " '',\n",
              " '2023',\n",
              " 'Tiruchirapalli',\n",
              " 'Comprehensive SQL training by GeeksforGeeks',\n",
              " '',\n",
              " 'Risk Prediction Using Machine Learning',\n",
              " 'The project predicts maternal health risks using machine learning models, focusing on data preprocessing, model training, and evaluation to classify risk levels accurately',\n",
              " '',\n",
              " '',\n",
              " 'EDUCATION',\n",
              " '',\n",
              " '',\n",
              " 'B.E BioMedical Engineering',\n",
              " 'Anna University',\n",
              " 'covering advanced querying, database management, and data manipulation techniques',\n",
              " '',\n",
              " '',\n",
              " 'PASSIONS',\n",
              " '',\n",
              " 'Data-Driven Storytelling',\n",
              " 'Passionate about transforming data into compelling stories that drive decision- making and strategy.',\n",
              " '',\n",
              " '2020 2024',\n",
              " 'Tiruchirapalli, TamilNadu',\n",
              " '',\n",
              " 'Continuous Learning',\n",
              " '',\n",
              " 'LANGUAGES',\n",
              " 'Committed to continually enhancing my data analysis skills through courses, workshops, and self-study.',\n",
              " '',\n",
              " 'Tamil English',\n",
              " 'Native Proficient']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text = \" \".join(text)"
      ],
      "metadata": {
        "id": "cHCRN2uUeHuV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "xctvkiZweSpD",
        "outputId": "e0b3525a-df71-4419-dfb4-41a3245fff09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BARATH KUMAR S Data Analyst | Data Visualization | SQL Expert barathkumar112003@gmail.com | LinkedIn - https://www.linkedin.com/in/barath55/ | Github - https://github.com/baaaRaathh/p y thons  HackerRank - https://www.hackerrank.com/dashboard  OBJECTIVE |Mob No - 6379109925 |Location - Tiruchirapalli ,Tamil Nadu  STRENGTHS   Eager to apply my data analysis skills in a dynamic environment. Skilled in SQL, Python, and data visualization. Aspiring to contribute to data-driven decision-making processes and eager to develop further in data analytics. EXPERIENCE  Data Science Intern KIWISTRON  Analytical Thinking Proven ability to analyze complex datasets, as demonstrated during my internship at IBM, leading to actionable insights.   Effective Communication Skilled in presenting complex data in an understandable format, evidenced by  2023 2024 Tiruchirapalli positive feedback from Accenture team  Internship focusing on data Science Analyzed large datasets using SQL and Python, identifying key trends and patterns, which improved data-driven decision-making by 30%. Developed and presented data-driven insights, improving stakeholder understanding of complex dataset.    leads.   Team Collaboration Excelled in team projects, contributing to a 20% improvement in data quality at  Python Intern SD Pro Solution 2023 2023    Cleveland, OH Accenture through effective collaboration.  SKILLS    Internship with a focus on python and Data Maniplution.  Experienced in Python for efficient data manipulation and analysis. Processed over 50 datasets using Python and SQL. Participated in a team project to enhance data quality, achieving a 20% improvement in data accuracy. SQL\\tPython\\tData Visualization      Tableau\\tPowerBi\\tExcel         PROJECTS   Artiﬁcial Intelligence Based Health Management App Data Manipulation Data Management Data Analysis   Report Generation     2024 Tiruchirapalli CERTIFICATION  AI-powered Health Management App for medical advice, image analysis, and nutrition tracking  Led a 4-member team to create an AI-powered Health Management App with a medical chatbot and image analyzer using the Google Gemini Pro API.   Maternal Health Risk Prediction Using Machine Learning Applied Data Science Completed an in-depth course on Applied Data Science through Coursera, with a strong focus on complex data analysis, manipulation, and advanced querying techniques    SQL  2023 Tiruchirapalli Comprehensive SQL training by GeeksforGeeks  Risk Prediction Using Machine Learning The project predicts maternal health risks using machine learning models, focusing on data preprocessing, model training, and evaluation to classify risk levels accurately   EDUCATION   B.E BioMedical Engineering Anna University covering advanced querying, database management, and data manipulation techniques   PASSIONS  Data-Driven Storytelling Passionate about transforming data into compelling stories that drive decision- making and strategy.  2020 2024 Tiruchirapalli, TamilNadu  Continuous Learning  LANGUAGES Committed to continually enhancing my data analysis skills through courses, workshops, and self-study.  Tamil English Native Proficient'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting data from Json File"
      ],
      "metadata": {
        "id": "dt8RlyhQe1z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "S_3DJSpgeUZW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = \"iris.json\"\n",
        "with open(r) as file:\n",
        "  data = json.load(file)"
      ],
      "metadata": {
        "id": "fqzQm21nhQdj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cDkSYS7jse8",
        "outputId": "999acdf6-0147-445f-a1a0-c0869782ca29"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.5,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.9,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.7,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.6,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.6,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.4,\n",
              "  'sepalWidth': 3.9,\n",
              "  'petalLength': 1.7,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.6,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.4,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.9,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.1,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.4,\n",
              "  'sepalWidth': 3.7,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.8,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.8,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.1,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.3,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 1.1,\n",
              "  'petalWidth': 0.1,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 4.0,\n",
              "  'petalLength': 1.2,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 4.4,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.4,\n",
              "  'sepalWidth': 3.9,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.5,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 3.8,\n",
              "  'petalLength': 1.7,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.8,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.4,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.7,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.7,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.6,\n",
              "  'sepalWidth': 3.6,\n",
              "  'petalLength': 1.0,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.3,\n",
              "  'petalLength': 1.7,\n",
              "  'petalWidth': 0.5,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.8,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.9,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.2,\n",
              "  'sepalWidth': 3.5,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.2,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.7,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.8,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.4,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.2,\n",
              "  'sepalWidth': 4.1,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.1,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 4.2,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.9,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 1.2,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 3.5,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.9,\n",
              "  'sepalWidth': 3.6,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.1,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.4,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.5,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.5,\n",
              "  'sepalWidth': 2.3,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.4,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 1.3,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.5,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.6,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.8,\n",
              "  'petalLength': 1.9,\n",
              "  'petalWidth': 0.4,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.8,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.3,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 3.8,\n",
              "  'petalLength': 1.6,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 4.6,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.3,\n",
              "  'sepalWidth': 3.7,\n",
              "  'petalLength': 1.5,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 3.3,\n",
              "  'petalLength': 1.4,\n",
              "  'petalWidth': 0.2,\n",
              "  'species': 'setosa'},\n",
              " {'sepalLength': 7.0,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 4.7,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.9,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 4.9,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 2.3,\n",
              "  'petalLength': 4.0,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.5,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.6,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 3.3,\n",
              "  'petalLength': 4.7,\n",
              "  'petalWidth': 1.6,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 4.9,\n",
              "  'sepalWidth': 2.4,\n",
              "  'petalLength': 3.3,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.6,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 4.6,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.2,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 3.9,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 2.0,\n",
              "  'petalLength': 3.5,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.9,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.2,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.0,\n",
              "  'sepalWidth': 2.2,\n",
              "  'petalLength': 4.0,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.1,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 4.7,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.6,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 3.6,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 4.4,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.6,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 4.1,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.2,\n",
              "  'sepalWidth': 2.2,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.6,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 3.9,\n",
              "  'petalWidth': 1.1,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.9,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 4.8,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.1,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.0,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 4.9,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.1,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.7,\n",
              "  'petalWidth': 1.2,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 4.3,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.6,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.4,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.8,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.8,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.0,\n",
              "  'petalWidth': 1.7,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.0,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 2.6,\n",
              "  'petalLength': 3.5,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 2.4,\n",
              "  'petalLength': 3.8,\n",
              "  'petalWidth': 1.1,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 2.4,\n",
              "  'petalLength': 3.7,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 3.9,\n",
              "  'petalWidth': 1.2,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.0,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 1.6,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.4,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.0,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.6,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 4.7,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 2.3,\n",
              "  'petalLength': 4.4,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.6,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.1,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 4.0,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.5,\n",
              "  'sepalWidth': 2.6,\n",
              "  'petalLength': 4.4,\n",
              "  'petalWidth': 1.2,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.1,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.6,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 2.6,\n",
              "  'petalLength': 4.0,\n",
              "  'petalWidth': 1.2,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.0,\n",
              "  'sepalWidth': 2.3,\n",
              "  'petalLength': 3.3,\n",
              "  'petalWidth': 1.0,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.6,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 4.2,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.2,\n",
              "  'petalWidth': 1.2,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 4.2,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.2,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 4.3,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.1,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 3.0,\n",
              "  'petalWidth': 1.1,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.1,\n",
              "  'petalWidth': 1.3,\n",
              "  'species': 'versicolor'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 3.3,\n",
              "  'petalLength': 6.0,\n",
              "  'petalWidth': 2.5,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 1.9,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.1,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.9,\n",
              "  'petalWidth': 2.1,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 5.6,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.5,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.8,\n",
              "  'petalWidth': 2.2,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.6,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 6.6,\n",
              "  'petalWidth': 2.1,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 4.9,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 4.5,\n",
              "  'petalWidth': 1.7,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.3,\n",
              "  'sepalWidth': 2.9,\n",
              "  'petalLength': 6.3,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 5.8,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.2,\n",
              "  'sepalWidth': 3.6,\n",
              "  'petalLength': 6.1,\n",
              "  'petalWidth': 2.5,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.5,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 2.0,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 5.3,\n",
              "  'petalWidth': 1.9,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.8,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.5,\n",
              "  'petalWidth': 2.1,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 5.7,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 5.0,\n",
              "  'petalWidth': 2.0,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 2.4,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 5.3,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.5,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.5,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.7,\n",
              "  'sepalWidth': 3.8,\n",
              "  'petalLength': 6.7,\n",
              "  'petalWidth': 2.2,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.7,\n",
              "  'sepalWidth': 2.6,\n",
              "  'petalLength': 6.9,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.0,\n",
              "  'sepalWidth': 2.2,\n",
              "  'petalLength': 5.0,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.9,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 5.7,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 5.6,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.9,\n",
              "  'petalWidth': 2.0,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.7,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 6.7,\n",
              "  'petalWidth': 2.0,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 4.9,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.3,\n",
              "  'petalLength': 5.7,\n",
              "  'petalWidth': 2.1,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.2,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 6.0,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.2,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 4.8,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.1,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.9,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 5.6,\n",
              "  'petalWidth': 2.1,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.2,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.8,\n",
              "  'petalWidth': 1.6,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.4,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 6.1,\n",
              "  'petalWidth': 1.9,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.9,\n",
              "  'sepalWidth': 3.8,\n",
              "  'petalLength': 6.4,\n",
              "  'petalWidth': 2.0,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 5.6,\n",
              "  'petalWidth': 2.2,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 2.8,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 1.5,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.1,\n",
              "  'sepalWidth': 2.6,\n",
              "  'petalLength': 5.6,\n",
              "  'petalWidth': 1.4,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 7.7,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 6.1,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 5.6,\n",
              "  'petalWidth': 2.4,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.4,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 5.5,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.0,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 4.8,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.9,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 5.4,\n",
              "  'petalWidth': 2.1,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 5.6,\n",
              "  'petalWidth': 2.4,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.9,\n",
              "  'sepalWidth': 3.1,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 5.8,\n",
              "  'sepalWidth': 2.7,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 1.9,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.8,\n",
              "  'sepalWidth': 3.2,\n",
              "  'petalLength': 5.9,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.3,\n",
              "  'petalLength': 5.7,\n",
              "  'petalWidth': 2.5,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.7,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.2,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.3,\n",
              "  'sepalWidth': 2.5,\n",
              "  'petalLength': 5.0,\n",
              "  'petalWidth': 1.9,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.5,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.2,\n",
              "  'petalWidth': 2.0,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 6.2,\n",
              "  'sepalWidth': 3.4,\n",
              "  'petalLength': 5.4,\n",
              "  'petalWidth': 2.3,\n",
              "  'species': 'virginica'},\n",
              " {'sepalLength': 5.9,\n",
              "  'sepalWidth': 3.0,\n",
              "  'petalLength': 5.1,\n",
              "  'petalWidth': 1.8,\n",
              "  'species': 'virginica'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect data from Html"
      ],
      "metadata": {
        "id": "l7kbnWOooVCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as urllibe\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "dqQ6MSI_kTJ_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responce = urllibe.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
        "ht = responce.read()\n",
        "soup = BeautifulSoup(ht,'html.parser')"
      ],
      "metadata": {
        "id": "9YM2NDnkomwq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st = soup.prettify()\n",
        "print(st[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ML7NptpEu1",
        "outputId": "5d60dd2f-ef88-416b-ce32-90bb31c3ea7e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-toc-available\" dir=\"ltr\" lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <title>\n",
            "   Natural language processing - Wikipedia\n",
            "  </title>\n",
            "  <script>\n",
            "   (function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.title)\n",
        "print(soup.title.string)\n",
        "print(soup.a.string)\n",
        "print(soup.b.string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huLgpU9qpLgE",
        "outputId": "3511ef3a-34e1-4444-e80c-9f114e28c0dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<title>Natural language processing - Wikipedia</title>\n",
            "Natural language processing - Wikipedia\n",
            "Jump to content\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting all instance of a particular tag\n",
        "for i in soup.find_all('a'):  print(i.string)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUnFl80GpgfX",
        "outputId": "69ad79db-0e0e-4e09-aac8-289f4708343a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jump to content\n",
            "Main page\n",
            "Contents\n",
            "Current events\n",
            "Random article\n",
            "About Wikipedia\n",
            "Contact us\n",
            "Help\n",
            "Learn to edit\n",
            "Community portal\n",
            "Recent changes\n",
            "Upload file\n",
            "None\n",
            "None\n",
            "Donate\n",
            "Create account\n",
            "Log in\n",
            "None\n",
            "None\n",
            "learn more\n",
            "Contributions\n",
            "Talk\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "Afrikaans\n",
            "العربية\n",
            "Արեւմտահայերէն\n",
            "Azərbaycanca\n",
            "বাংলা\n",
            "閩南語 / Bân-lâm-gú\n",
            "Беларуская\n",
            "Беларуская (тарашкевіца)\n",
            "Български\n",
            "Bosanski\n",
            "Brezhoneg\n",
            "Català\n",
            "Čeština\n",
            "Cymraeg\n",
            "Dansk\n",
            "Deutsch\n",
            "Eesti\n",
            "Ελληνικά\n",
            "Español\n",
            "Esperanto\n",
            "Euskara\n",
            "فارسی\n",
            "Français\n",
            "Gaeilge\n",
            "Galego\n",
            "한국어\n",
            "Հայերեն\n",
            "हिन्दी\n",
            "Hrvatski\n",
            "Bahasa Indonesia\n",
            "IsiZulu\n",
            "Íslenska\n",
            "Italiano\n",
            "עברית\n",
            "ಕನ್ನಡ\n",
            "ქართული\n",
            "Latviešu\n",
            "Lietuvių\n",
            "Македонски\n",
            "मराठी\n",
            "مصرى\n",
            "Монгол\n",
            "မြန်မာဘာသာ\n",
            "日本語\n",
            "ଓଡ଼ିଆ\n",
            "پښتو\n",
            "Picard\n",
            "Piemontèis\n",
            "Polski\n",
            "Português\n",
            "Qaraqalpaqsha\n",
            "Română\n",
            "Runa Simi\n",
            "Русский\n",
            "Shqip\n",
            "Simple English\n",
            "کوردی\n",
            "Српски / srpski\n",
            "Srpskohrvatski / српскохрватски\n",
            "Suomi\n",
            "தமிழ்\n",
            "తెలుగు\n",
            "ไทย\n",
            "Türkçe\n",
            "Українська\n",
            "Tiếng Việt\n",
            "粵語\n",
            "中文\n",
            "Edit links\n",
            "Article\n",
            "Talk\n",
            "Read\n",
            "Edit\n",
            "View history\n",
            "Read\n",
            "Edit\n",
            "View history\n",
            "What links here\n",
            "Related changes\n",
            "Upload file\n",
            "Special pages\n",
            "Permanent link\n",
            "Page information\n",
            "Cite this page\n",
            "Get shortened URL\n",
            "Download QR code\n",
            "Wikidata item\n",
            "Download as PDF\n",
            "Printable version\n",
            "Wikimedia Commons\n",
            "Wikiversity\n",
            "NLP\n",
            "Language processing in the brain\n",
            "None\n",
            "verification\n",
            "improve this article\n",
            "adding citations to reliable sources\n",
            "\"Natural language processing\"\n",
            "news\n",
            "newspapers\n",
            "books\n",
            "scholar\n",
            "JSTOR\n",
            "Learn how and when to remove this message\n",
            "computer science\n",
            "artificial intelligence\n",
            "natural language\n",
            "information retrieval\n",
            "knowledge representation\n",
            "computational linguistics\n",
            "linguistics\n",
            "text corpora\n",
            "machine learning\n",
            "deep learning\n",
            "speech recognition\n",
            "text classification\n",
            "natural-language understanding\n",
            "natural-language generation\n",
            "edit\n",
            "History of natural language processing\n",
            "None\n",
            "Alan Turing\n",
            "Computing Machinery and Intelligence\n",
            "Turing test\n",
            "edit\n",
            "John Searle\n",
            "Chinese room\n",
            "Georgetown experiment\n",
            "automatic translation\n",
            "None\n",
            "ALPAC report\n",
            "None\n",
            "statistical machine translation\n",
            "SHRDLU\n",
            "blocks worlds\n",
            "ELIZA\n",
            "Rogerian psychotherapist\n",
            "Joseph Weizenbaum\n",
            "Ross Quillian\n",
            "None\n",
            "ontologies\n",
            "chatterbots\n",
            "PARRY\n",
            "HPSG\n",
            "generative grammar\n",
            "None\n",
            "Lesk algorithm\n",
            "None\n",
            "Rhetorical Structure Theory\n",
            "Racter\n",
            "Jabberwacky\n",
            "None\n",
            "edit\n",
            "machine learning\n",
            "Moore's law\n",
            "Chomskyan\n",
            "transformational grammar\n",
            "corpus linguistics\n",
            "None\n",
            "machine translation\n",
            "IBM alignment models\n",
            "textual corpora\n",
            "Parliament of Canada\n",
            "European Union\n",
            "unsupervised\n",
            "semi-supervised learning\n",
            "supervised learning\n",
            "World Wide Web\n",
            "time complexity\n",
            "edit\n",
            "word n-gram model\n",
            "multi-layer perceptron\n",
            "language modelling\n",
            "Yoshua Bengio\n",
            "None\n",
            "Tomáš Mikolov\n",
            "Brno University of Technology\n",
            "recurrent neural network\n",
            "None\n",
            "Word2vec\n",
            "representation learning\n",
            "deep neural network\n",
            "None\n",
            "None\n",
            "language modeling\n",
            "None\n",
            "None\n",
            "None\n",
            "in medicine and healthcare\n",
            "electronic health records\n",
            "None\n",
            "None\n",
            "edit\n",
            "None\n",
            "None\n",
            "stemming\n",
            "Machine learning\n",
            "language models\n",
            "intractability\n",
            "LLMs\n",
            "Apertium\n",
            "tokenization\n",
            "knowledge extraction\n",
            "edit\n",
            "AI winter\n",
            "None\n",
            "None\n",
            "decision trees\n",
            "if–then rules\n",
            "Markov models\n",
            "edit\n",
            "Artificial neural network\n",
            "feature engineering\n",
            "None\n",
            "neural networks\n",
            "semantic networks\n",
            "None\n",
            "word embeddings\n",
            "Neural machine translation\n",
            "sequence-to-sequence\n",
            "statistical machine translation\n",
            "edit\n",
            "edit\n",
            "Optical character recognition\n",
            "Speech recognition\n",
            "text to speech\n",
            "AI-complete\n",
            "natural speech\n",
            "speech segmentation\n",
            "coarticulation\n",
            "analog signal\n",
            "Speech segmentation\n",
            "speech recognition\n",
            "Text-to-speech\n",
            "None\n",
            "Word segmentation\n",
            "Tokenization\n",
            "None\n",
            "English\n",
            "Chinese\n",
            "Japanese\n",
            "Thai\n",
            "vocabulary\n",
            "morphology\n",
            "bag of words\n",
            "citation needed\n",
            "edit\n",
            "Lemmatization\n",
            "None\n",
            "Morphological segmentation\n",
            "morphemes\n",
            "morphology\n",
            "English\n",
            "inflectional morphology\n",
            "Turkish\n",
            "Meitei\n",
            "agglutinated\n",
            "None\n",
            "Part-of-speech tagging\n",
            "part of speech\n",
            "noun\n",
            "verb\n",
            "adjective\n",
            "Stemming\n",
            "edit\n",
            "a series\n",
            "Formal languages\n",
            "Formal system\n",
            "Alphabet\n",
            "Syntax\n",
            "Semantics (logic)\n",
            "Semantics (programming languages)\n",
            "Formal grammar\n",
            "Formation rule\n",
            "Well-formed formula\n",
            "Automata theory\n",
            "Regular expression\n",
            "Production\n",
            "Ground expression\n",
            "Atomic formula\n",
            "Formal methods\n",
            "Propositional calculus\n",
            "Predicate logic\n",
            "Mathematical notation\n",
            "Natural language processing\n",
            "Programming language theory\n",
            "Computational linguistics\n",
            "Syntax analysis\n",
            "Formal verification\n",
            "Automated theorem proving\n",
            "v\n",
            "t\n",
            "e\n",
            "Grammar induction\n",
            "None\n",
            "formal grammar\n",
            "Sentence breaking\n",
            "sentence boundary disambiguation\n",
            "periods\n",
            "punctuation marks\n",
            "abbreviations\n",
            "Parsing\n",
            "parse tree\n",
            "grammar\n",
            "natural languages\n",
            "ambiguous\n",
            "probabilistic context-free grammar\n",
            "stochastic grammar\n",
            "edit\n",
            "Lexical semantics\n",
            "Distributional semantics\n",
            "Named entity recognition\n",
            "capitalization\n",
            "named entity\n",
            "Chinese\n",
            "Arabic\n",
            "German\n",
            "nouns\n",
            "French\n",
            "Spanish\n",
            "adjectives\n",
            "None\n",
            "Sentiment analysis\n",
            "Multimodal sentiment analysis\n",
            "word n-grams\n",
            "Term Frequency-Inverse Document Frequency\n",
            "deep learning\n",
            "None\n",
            "Terminology extraction\n",
            "Word-sense disambiguation\n",
            "meaning\n",
            "WordNet\n",
            "Entity linking\n",
            "named entities\n",
            "edit\n",
            "Relationship extraction\n",
            "Semantic parsing\n",
            "AMR parsing\n",
            "DRT parsing\n",
            "Natural language understanding\n",
            "Semantic role labelling\n",
            "frames\n",
            "semantic roles\n",
            "edit\n",
            "Coreference resolution\n",
            "Anaphora resolution\n",
            "pronouns\n",
            "referring expressions\n",
            "Discourse analysis\n",
            "discourse\n",
            "speech acts\n",
            "frames\n",
            "Semantic role labelling\n",
            "pro-drop languages\n",
            "Recognizing textual entailment\n",
            "None\n",
            "Topic segmentation\n",
            "Argument mining\n",
            "natural language\n",
            "None\n",
            "argument scheme\n",
            "None\n",
            "None\n",
            "edit\n",
            "Automatic summarization\n",
            "None\n",
            "None\n",
            "None\n",
            "GPT-2\n",
            "Logic translation\n",
            "Machine translation\n",
            "AI-complete\n",
            "Natural-language understanding\n",
            "first-order logic\n",
            "computer\n",
            "closed-world assumption\n",
            "open-world assumption\n",
            "None\n",
            "Natural-language generation\n",
            "None\n",
            "1 the Road\n",
            "language models\n",
            "None\n",
            "Document AI\n",
            "None\n",
            "Dialogue management\n",
            "Question answering\n",
            "Text-to-image generation\n",
            "None\n",
            "3D model\n",
            "None\n",
            "None\n",
            "Text-to-video\n",
            "None\n",
            "None\n",
            "edit\n",
            "None\n",
            "edit\n",
            "Cognition\n",
            "None\n",
            "Cognitive science\n",
            "None\n",
            "Cognitive linguistics\n",
            "None\n",
            "symbolic NLP\n",
            "George Lakoff\n",
            "None\n",
            "conceptual metaphor\n",
            "None\n",
            "probabilistic context-free grammar\n",
            "US Patent 9269353\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "ACT-R\n",
            "None\n",
            "ACL\n",
            "explainability\n",
            "None\n",
            "multimodal\n",
            "None\n",
            "artificial intelligence\n",
            "large language model\n",
            "None\n",
            "artificial general intelligence\n",
            "free energy principle\n",
            "None\n",
            "Karl J. Friston\n",
            "edit\n",
            "1 the Road\n",
            "Artificial intelligence detection software\n",
            "Automated essay scoring\n",
            "Biomedical text mining\n",
            "Compound term processing\n",
            "Computational linguistics\n",
            "Computer-assisted reviewing\n",
            "Controlled natural language\n",
            "Deep learning\n",
            "Deep linguistic processing\n",
            "Distributional semantics\n",
            "Foreign language reading aid\n",
            "Foreign language writing aid\n",
            "Information extraction\n",
            "Information retrieval\n",
            "Language and Communication Technologies\n",
            "Language model\n",
            "Language technology\n",
            "Latent semantic indexing\n",
            "Multi-agent system\n",
            "Native-language identification\n",
            "Natural-language programming\n",
            "Natural-language understanding\n",
            "Natural-language search\n",
            "Outline of natural language processing\n",
            "Query expansion\n",
            "Query understanding\n",
            "Reification (linguistics)\n",
            "Speech processing\n",
            "Spoken dialogue systems\n",
            "Text-proofing\n",
            "Text simplification\n",
            "Transformer (machine learning model)\n",
            "Truecasing\n",
            "Question answering\n",
            "Word2vec\n",
            "edit\n",
            "^\n",
            "\"NLP\"\n",
            "^\n",
            "\"The history of machine translation in a nutshell\"\n",
            "self-published source\n",
            "^\n",
            "^\n",
            "Crevier 1993\n",
            "help\n",
            "Buchanan 2005\n",
            "help\n",
            "^\n",
            "Koskenniemi, Kimmo\n",
            "Two-level morphology: A general computational model of word-form recognition and production\n",
            "University of Helsinki\n",
            "^\n",
            "Control of Inference: Role of Some Aspects of Discourse Structure-Centering\n",
            "^\n",
            "doi\n",
            "10.1109/PROC.1986.13580\n",
            "ISSN\n",
            "1558-2256\n",
            "S2CID\n",
            "30688575\n",
            "^\n",
            "corner cases\n",
            "pathological\n",
            "thought experiments\n",
            "corpus linguistics\n",
            "corpora\n",
            "poverty of the stimulus\n",
            "^\n",
            "\"A neural probabilistic language model\"\n",
            "^\n",
            "\"Recurrent neural network based language model\"\n",
            "doi\n",
            "10.21437/Interspeech.2010-343\n",
            "S2CID\n",
            "17048224\n",
            "cite book\n",
            "help\n",
            "^\n",
            "arXiv\n",
            "1807.10854\n",
            "doi\n",
            "10.1613/jair.4992\n",
            "S2CID\n",
            "8273530\n",
            "^\n",
            "Deep Learning\n",
            "^\n",
            "arXiv\n",
            "1602.02410\n",
            "Bibcode\n",
            "2016arXiv160202410J\n",
            "^\n",
            "\"Parsing as Language Modeling\"\n",
            "the original\n",
            "^\n",
            "\"Grammar as a Foreign Language\"\n",
            "arXiv\n",
            "1412.7449\n",
            "Bibcode\n",
            "2014arXiv1412.7449V\n",
            "^\n",
            "\"Using Natural Language Processing to Measure and Improve Quality of Diabetes Care: A Systematic Review\"\n",
            "doi\n",
            "10.1177/19322968211000831\n",
            "ISSN\n",
            "1932-2968\n",
            "PMC\n",
            "8120048\n",
            "PMID\n",
            "33736486\n",
            "^\n",
            "\"Prevalence of Sensitive Terms in Clinical Notes Using Natural Language Processing Techniques: Observational Study\"\n",
            "doi\n",
            "10.2196/38482\n",
            "ISSN\n",
            "2291-9694\n",
            "PMC\n",
            "9233261\n",
            "PMID\n",
            "35687381\n",
            "^\n",
            "Procedures as a Representation for Data in a Computer Program for Understanding Natural Language\n",
            "^\n",
            "ISBN\n",
            "0-470-99033-3\n",
            "^\n",
            "Mark Johnson. How the statistical revolution changes (computational) linguistics.\n",
            "^\n",
            "Philip Resnik. Four revolutions.\n",
            "^\n",
            "\"Deep Learning For NLP-ACL 2012 Tutorial\"\n",
            "http://web.stanford.edu/class/cs224n/\n",
            "^\n",
            "Semantic Network Analysis in Social Sciences\n",
            "ISBN\n",
            "9780367636524\n",
            "Archived\n",
            "^\n",
            "Tian, Yingli\n",
            "CiteSeerX\n",
            "10.1.1.668.869\n",
            "doi\n",
            "10.1007/978-3-642-29364-1_2\n",
            "ISBN\n",
            "9783642293634\n",
            "a\n",
            "b\n",
            "\"Natural Language Processing (NLP) - A Complete Guide\"\n",
            "^\n",
            "\"What is Natural Language Processing? Intro to NLP in Machine Learning\"\n",
            "^\n",
            "\"Manipuri Morpheme Identification\"\n",
            "cite journal\n",
            "link\n",
            "^\n",
            "\"Natural language grammar induction using a constituent-context model\"\n",
            "^\n",
            "\"Precision information extraction for rare disease epidemiology at scale\"\n",
            "doi\n",
            "10.1186/s12967-023-04011-y\n",
            "PMC\n",
            "9972634\n",
            "PMID\n",
            "36855134\n",
            "^\n",
            "https://tac.nist.gov//2011/RTE/\n",
            "^\n",
            "\"Argumentation Mining: State of the Art and Emerging Trends\"\n",
            "doi\n",
            "10.1145/2850417\n",
            "hdl\n",
            "11585/523460\n",
            "ISSN\n",
            "1533-5399\n",
            "S2CID\n",
            "9561587\n",
            "^\n",
            "\"Argument Mining – IJCAI2016 Tutorial\"\n",
            "^\n",
            "\"NLP Approaches to Computational Argumentation – ACL 2016, Berlin\"\n",
            "^\n",
            "\"Centre for Language Technology (CLT)\"\n",
            "^\n",
            "\"Shared Task: Grammatical Error Correction\"\n",
            "^\n",
            "\"Shared Task: Grammatical Error Correction\"\n",
            "^\n",
            "\"Formalizing Semantic of Natural Language through Conceptualization from Existence\"\n",
            "the original\n",
            "^\n",
            "\"U B U W E B :: Racter\"\n",
            "^\n",
            "doi\n",
            "10.1007/978-3-030-16800-1\n",
            "ISBN\n",
            "978-3-030-16799-8\n",
            "S2CID\n",
            "155818532\n",
            "^\n",
            "\"Document Understanding AI on Google Cloud (Cloud Next '19) – YouTube\"\n",
            "the original\n",
            "^\n",
            "\"OpenAI's DALL-E AI image generator can now edit pictures, too\"\n",
            "^\n",
            "\"The Stanford Natural Language Processing Group\"\n",
            "^\n",
            "\"WordsEye\"\n",
            "doi\n",
            "10.1145/383259.383316\n",
            "ISBN\n",
            "978-1-58113-374-5\n",
            "S2CID\n",
            "3842372\n",
            "^\n",
            "\"Google announces AI advances in text-to-video, language translation, more\"\n",
            "^\n",
            "\"Meta's new text-to-video AI generator is like DALL-E for video\"\n",
            "^\n",
            "\"Previous shared tasks | CoNLL\"\n",
            "^\n",
            "\"Cognition\"\n",
            "Oxford University Press\n",
            "Dictionary.com\n",
            "the original\n",
            "^\n",
            "\"Ask the Cognitive Scientist\"\n",
            "^\n",
            "ISBN\n",
            "978-0-805-85352-0\n",
            "^\n",
            "ISBN\n",
            "978-0-465-05674-3\n",
            "^\n",
            "ISBN\n",
            "978-0-521-59541-4\n",
            "^\n",
            "US patent 9269353\n",
            "^\n",
            "\"Universal Conceptual Cognitive Annotation (UCCA)\"\n",
            "^\n",
            "Building an RRG computational grammar\n",
            "^\n",
            "\"Fluid Construction Grammar – A fully operational processing system for construction grammars\"\n",
            "^\n",
            "\"ACL Member Portal | The Association for Computational Linguistics Member Portal\"\n",
            "^\n",
            "\"Chunks and Rules\"\n",
            "^\n",
            "\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\"\n",
            "doi\n",
            "10.1162/tacl_a_00177\n",
            "S2CID\n",
            "2317858\n",
            "^\n",
            "arXiv\n",
            "2207.07051\n",
            "cs.CL\n",
            "^\n",
            "ISBN\n",
            "978-0-262-36997-8\n",
            "edit\n",
            "\"Models of natural language understanding\"\n",
            "Bibcode\n",
            "1995PNAS...92.9977B\n",
            "doi\n",
            "10.1073/pnas.92.22.9977\n",
            "PMC\n",
            "40721\n",
            "PMID\n",
            "7479812\n",
            "ISBN\n",
            "978-0-596-51649-9\n",
            "Kenna Hughes-Castleberry\n",
            "Cain's Jawbone\n",
            "Scientific American\n",
            "natural-language processing\n",
            "context\n",
            "ancient languages\n",
            "civilizations\n",
            "training data\n",
            "ISBN\n",
            "978-0-13-187321-6\n",
            "ISBN\n",
            "978-1848218482\n",
            "ISBN\n",
            "978-1848219212\n",
            "ISBN\n",
            "978-0-521-86571-5\n",
            "Official html and pdf versions available without charge.\n",
            "ISBN\n",
            "978-0-262-13360-9\n",
            "ISBN\n",
            "978-0-387-19557-5\n",
            "edit\n",
            "None\n",
            "Natural language processing\n",
            "v\n",
            "t\n",
            "e\n",
            "Natural language processing\n",
            "AI-complete\n",
            "Bag-of-words\n",
            "n-gram\n",
            "Bigram\n",
            "Trigram\n",
            "Computational linguistics\n",
            "Natural language understanding\n",
            "Stop words\n",
            "Text processing\n",
            "Text analysis\n",
            "Argument mining\n",
            "Collocation extraction\n",
            "Concept mining\n",
            "Coreference resolution\n",
            "Deep linguistic processing\n",
            "Distant reading\n",
            "Information extraction\n",
            "Named-entity recognition\n",
            "Ontology learning\n",
            "Parsing\n",
            "Semantic parsing\n",
            "Syntactic parsing\n",
            "Part-of-speech tagging\n",
            "Semantic analysis\n",
            "Semantic role labeling\n",
            "Semantic decomposition\n",
            "Semantic similarity\n",
            "Sentiment analysis\n",
            "Terminology extraction\n",
            "Text mining\n",
            "Textual entailment\n",
            "Truecasing\n",
            "Word-sense disambiguation\n",
            "Word-sense induction\n",
            "Text segmentation\n",
            "Compound-term processing\n",
            "Lemmatisation\n",
            "Lexical analysis\n",
            "Text chunking\n",
            "Stemming\n",
            "Sentence segmentation\n",
            "Word segmentation\n",
            "Automatic summarization\n",
            "Multi-document summarization\n",
            "Sentence extraction\n",
            "Text simplification\n",
            "Machine translation\n",
            "Computer-assisted\n",
            "Example-based\n",
            "Rule-based\n",
            "Statistical\n",
            "Transfer-based\n",
            "Neural\n",
            "Distributional semantics\n",
            "BERT\n",
            "Document-term matrix\n",
            "Explicit semantic analysis\n",
            "fastText\n",
            "GloVe\n",
            "Language model\n",
            "large\n",
            "Latent semantic analysis\n",
            "Seq2seq\n",
            "Word embedding\n",
            "Word2vec\n",
            "Language resources\n",
            "Corpus linguistics\n",
            "Lexical resource\n",
            "Linguistic Linked Open Data\n",
            "Machine-readable dictionary\n",
            "Parallel text\n",
            "PropBank\n",
            "Semantic network\n",
            "Simple Knowledge Organization System\n",
            "Speech corpus\n",
            "Text corpus\n",
            "Thesaurus (information retrieval)\n",
            "Treebank\n",
            "Universal Dependencies\n",
            "BabelNet\n",
            "Bank of English\n",
            "DBpedia\n",
            "FrameNet\n",
            "Google Ngram Viewer\n",
            "UBY\n",
            "WordNet\n",
            "Wikidata\n",
            "None\n",
            "Speech recognition\n",
            "Speech segmentation\n",
            "Speech synthesis\n",
            "Natural language generation\n",
            "Optical character recognition\n",
            "Topic model\n",
            "Document classification\n",
            "Latent Dirichlet allocation\n",
            "Pachinko allocation\n",
            "None\n",
            "Automated essay scoring\n",
            "Concordancer\n",
            "Grammar checker\n",
            "Predictive text\n",
            "Pronunciation assessment\n",
            "Spell checker\n",
            "None\n",
            "Chatbot\n",
            "Interactive fiction\n",
            "Syntax guessing\n",
            "Question answering\n",
            "Virtual assistant\n",
            "Voice user interface\n",
            "Formal semantics\n",
            "Hallucination\n",
            "Natural Language Toolkit\n",
            "spaCy\n",
            "Portal\n",
            "None\n",
            "Language\n",
            "Authority control databases\n",
            "None\n",
            "United States\n",
            "Japan\n",
            "Czech Republic\n",
            "Israel\n",
            "https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1251092666\n",
            "Categories\n",
            "Natural language processing\n",
            "Computational fields of study\n",
            "Computational linguistics\n",
            "Speech recognition\n",
            "All accuracy disputes\n",
            "Accuracy disputes from December 2013\n",
            "Harv and Sfn no-target errors\n",
            "CS1 errors: periodical ignored\n",
            "CS1 maint: location\n",
            "Articles with short description\n",
            "Short description is different from Wikidata\n",
            "Articles needing additional references from May 2024\n",
            "All articles needing additional references\n",
            "All articles with unsourced statements\n",
            "Articles with unsourced statements from May 2024\n",
            "Commons category link from Wikidata\n",
            "Creative Commons Attribution-ShareAlike 4.0 License\n",
            "Terms of Use\n",
            "Privacy Policy\n",
            "Wikimedia Foundation, Inc.\n",
            "Privacy policy\n",
            "About Wikipedia\n",
            "Disclaimers\n",
            "Contact Wikipedia\n",
            "Code of Conduct\n",
            "Developers\n",
            "Statistics\n",
            "Cookie statement\n",
            "Mobile view\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in soup.find_all('p'):print(i.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK3XdlCpqIJ0",
        "outputId": "2b04b049-5d04-44a5-db57-15f02d242501"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learning.\n",
            "\n",
            "Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\n",
            "\n",
            "Natural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n",
            "\n",
            "The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n",
            "\n",
            "Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\n",
            "\n",
            "In 2003, word n-gram model, at the time the best statistical algorithm, was outperformed by a multi-layer perceptron (with a single hidden layer and context length of several words trained on up to 14 million of words with a CPU cluster in language modelling) by Yoshua Bengio with co-authors.[9]\n",
            "\n",
            "In 2010, Tomáš Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling,[10] and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. That popularity was due partly to a flurry of results showing that such techniques[11][12] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[13] and parsing.[14][15] This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care[16] or protect patient privacy.[17]\n",
            "\n",
            "Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\n",
            "\n",
            "Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \n",
            "\n",
            "Although rule-based systems for manipulating symbols were still in use in 2020, they have become mostly obsolete with the advance of LLMs in 2023. \n",
            "\n",
            "Before that they were commonly used:\n",
            "\n",
            "In the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\n",
            "\n",
            "The earliest decision trees, producing systems of hard if–then rules, were still very similar to the old rule-based approaches.\n",
            "Only the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\n",
            "\n",
            "A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.  \n",
            "\n",
            "Intermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \n",
            "\n",
            "Neural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\n",
            "\n",
            "The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\n",
            "\n",
            "Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n",
            "\n",
            "Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[46]\n",
            "\n",
            "Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\n",
            "\n",
            "Cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[47] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[48] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[49] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\n",
            "\n",
            "As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:\n",
            "\n",
            "Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#parsing text using Expression"
      ],
      "metadata": {
        "id": "70-YCRuQq7qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting mail ID\n",
        "import re\n",
        "doc = 'for more details please mail us at :xycsidbcuy@abc.com,poejdiocnwoi@mnqo.com'\n",
        "address = re.findall(r\"[\\w\\.-]+@[\\w\\.-]+\",doc)"
      ],
      "metadata": {
        "id": "nGsz0LQOqV_6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAwb_dJ_rkuB",
        "outputId": "3295de74-757c-4085-9d75-24e54475b982"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xycsidbcuy@abc.com', 'poejdiocnwoi@mnqo.com']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace email Id\n",
        "new = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\",r\"barathkumar112003@gmail.com\",doc)"
      ],
      "metadata": {
        "id": "yaZl6T00rmsd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tTp5vK4_sA8-",
        "outputId": "2b96580c-4c56-49ee-fc60-8c054d7a76dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for more details please mail us at :barathkumar112003@gmail.com,barathkumar112003@gmail.com'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S51oSlK9sGuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping"
      ],
      "metadata": {
        "id": "NQ_x_IZysRmn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9Vb326MsVYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}